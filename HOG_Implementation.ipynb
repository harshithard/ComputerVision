{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HOG Implementation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshithard/ComputerVision/blob/main/HOG_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxRoHC7SDZ5g",
        "outputId": "1623e3ae-99b7-49b9-be83-e3f2ce1b2116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt   \n",
        "import time           \n",
        "import numpy as np  \n",
        "import os\n",
        "import math\n",
        "import random\n",
        "from numpy import savetxt\n",
        "\n",
        "parent = \"/content/drive/MyDrive/CV project 2\"\n",
        "\n",
        "#parent = \"Image Data\"\n",
        "\n",
        "#reading all the positive training images\n",
        "path = parent + \"/Training images (Pos)/\"\n",
        "Train_pos = [path+i for i in os.listdir(path)]\n",
        "\n",
        "path = parent + \"/Training images (Neg)/\"\n",
        "Train_neg = [path+i for i in os.listdir(path)]\n",
        "\n",
        "path = parent + \"/Test images (Pos)/\"\n",
        "Test_pos =[path+i for i in os.listdir(path)]\n",
        "\n",
        "path= parent + \"/Test images (Neg)/\"\n",
        "Test_neg = [path+i for i in os.listdir(path)]\n",
        "\n",
        "print(Train_neg)\n",
        "print(Train_pos)\n",
        "print(Test_pos)\n",
        "print(Test_neg)\n",
        "\n",
        "#Converting all the images to gray_scale\n",
        "def convert_to_gray(img): \n",
        "  #print(img)\n",
        "  prop = img.shape\n",
        "  \n",
        "  #print(img[0][0])\n",
        "  gray_img = np.zeros([img.shape[0],img.shape[1]])\n",
        "  for i in range(prop[0]):\n",
        "      for j in range( prop[1]):\n",
        "          gray_img[i][j] = np.round(0.114*img[i][j][2] + 0.587*img[i][j][1] + 0.299*img[i][j][0])\n",
        "  return gray_img"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnLoVVCcD_4H",
        "outputId": "c2018538-14f9-43c3-8862-58813c87ed2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/CV project 2/Training images (Neg)/01-03e_cut.bmp', '/content/drive/MyDrive/CV project 2/Training images (Neg)/00000057a_cut.bmp', '/content/drive/MyDrive/CV project 2/Training images (Neg)/00000091a_cut.bmp', '/content/drive/MyDrive/CV project 2/Training images (Neg)/no_person__no_bike_219_cut.bmp', '/content/drive/MyDrive/CV project 2/Training images (Neg)/no_person__no_bike_259_cut.bmp', '/content/drive/MyDrive/CV project 2/Training images (Neg)/00000053a_cut.bmp', '/content/drive/MyDrive/CV project 2/Training images (Neg)/00000062a_cut.bmp', '/content/drive/MyDrive/CV project 2/Training images (Neg)/00000093a_cut.bmp', '/content/drive/MyDrive/CV project 2/Training images (Neg)/no_person__no_bike_213_cut.bmp', '/content/drive/MyDrive/CV project 2/Training images (Neg)/no_person__no_bike_247_cut.bmp', '/content/drive/MyDrive/CV project 2/Training images (Neg)/01-03e_cut.txt', '/content/drive/MyDrive/CV project 2/Training images (Neg)/00000057a_cut.txt', '/content/drive/MyDrive/CV project 2/Training images (Neg)/00000091a_cut.txt', '/content/drive/MyDrive/CV project 2/Training images (Neg)/no_person__no_bike_219_cut.txt', '/content/drive/MyDrive/CV project 2/Training images (Neg)/no_person__no_bike_259_cut.txt', '/content/drive/MyDrive/CV project 2/Training images (Neg)/00000053a_cut.txt', '/content/drive/MyDrive/CV project 2/Training images (Neg)/00000062a_cut.txt', '/content/drive/MyDrive/CV project 2/Training images (Neg)/00000093a_cut.txt', '/content/drive/MyDrive/CV project 2/Training images (Neg)/no_person__no_bike_213_cut.txt', '/content/drive/MyDrive/CV project 2/Training images (Neg)/no_person__no_bike_247_cut.txt']\n",
            "['/content/drive/MyDrive/CV project 2/Training images (Pos)/crop001030c.bmp', '/content/drive/MyDrive/CV project 2/Training images (Pos)/crop001063b.bmp', '/content/drive/MyDrive/CV project 2/Training images (Pos)/crop001275b.bmp', '/content/drive/MyDrive/CV project 2/Training images (Pos)/crop001672b.bmp', '/content/drive/MyDrive/CV project 2/Training images (Pos)/person_and_bike_026a.bmp', '/content/drive/MyDrive/CV project 2/Training images (Pos)/crop_000010b.bmp', '/content/drive/MyDrive/CV project 2/Training images (Pos)/crop001028a.bmp', '/content/drive/MyDrive/CV project 2/Training images (Pos)/crop001047b.bmp', '/content/drive/MyDrive/CV project 2/Training images (Pos)/crop001008b.bmp', '/content/drive/MyDrive/CV project 2/Training images (Pos)/crop001045b.bmp', '/content/drive/MyDrive/CV project 2/Training images (Pos)/crop001030c.txt', '/content/drive/MyDrive/CV project 2/Training images (Pos)/crop001063b.txt', '/content/drive/MyDrive/CV project 2/Training images (Pos)/crop001672b.txt', '/content/drive/MyDrive/CV project 2/Training images (Pos)/crop001275b.txt', '/content/drive/MyDrive/CV project 2/Training images (Pos)/crop_000010b.txt', '/content/drive/MyDrive/CV project 2/Training images (Pos)/person_and_bike_026a.txt', '/content/drive/MyDrive/CV project 2/Training images (Pos)/crop001028a.txt', '/content/drive/MyDrive/CV project 2/Training images (Pos)/crop001047b.txt', '/content/drive/MyDrive/CV project 2/Training images (Pos)/crop001008b.txt', '/content/drive/MyDrive/CV project 2/Training images (Pos)/crop001045b.txt']\n",
            "['/content/drive/MyDrive/CV project 2/Test images (Pos)/crop001034b.bmp', '/content/drive/MyDrive/CV project 2/Test images (Pos)/crop001070a.bmp', '/content/drive/MyDrive/CV project 2/Test images (Pos)/crop001278a.bmp', '/content/drive/MyDrive/CV project 2/Test images (Pos)/crop001500b.bmp', '/content/drive/MyDrive/CV project 2/Test images (Pos)/person_and_bike_151a.bmp']\n",
            "['/content/drive/MyDrive/CV project 2/Test images (Neg)/00000003a_cut.bmp', '/content/drive/MyDrive/CV project 2/Test images (Neg)/00000090a_cut.bmp', '/content/drive/MyDrive/CV project 2/Test images (Neg)/00000118a_cut.bmp', '/content/drive/MyDrive/CV project 2/Test images (Neg)/no_person__no_bike_258_Cut.bmp', '/content/drive/MyDrive/CV project 2/Test images (Neg)/no_person__no_bike_264_cut.bmp']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying Prewitt's operator\n",
        "def prewitt_operator(gray_img):\n",
        "  h, w = np.shape(gray_img)[0], np.shape(gray_img)[1]\n",
        "  # define filters\n",
        "  horizontal = np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]])  # s2\n",
        "  vertical = np.array([[1, 1, 1], [0, 0, 0], [-1, -1, -1]])  # s1\n",
        "  # define images with 0s\n",
        "  newgradientImage = np.zeros((h, w))\n",
        "  gradient_angles = np.zeros((h, w))\n",
        "  horizontalGrad = np.zeros((h, w))\n",
        "  verticalGrad = np.zeros((h, w))\n",
        "\n",
        "  # offset by 1\n",
        "  for i in range(1, h - 1):\n",
        "      for j in range(1, w - 1):\n",
        "        horizontalGrad[i][j] = np.sum(np.multiply(gray_img[i-1:i+2,j-1:j+2],horizontal))\n",
        "        #print(gray_img[i-1:i+2,j-1:j+2])\n",
        "        verticalGrad[i][j] = np.sum(np.multiply(gray_img[i-1:i+2,j-1:j+2],vertical))\n",
        "          #print(verticalGrad,horizontalGrad)\n",
        "        #print(horizontalGrad)\n",
        "        #print(verticalGrad)\n",
        "        mag = (np.sqrt(pow(horizontalGrad[i][j], 2.0) + pow(verticalGrad[i][j], 2.0)))\n",
        "        #print(mag)\n",
        "        #mag = abs(horizontalGrad[i][j])+abs(verticalGrad[i][j])\n",
        "        if(horizontalGrad[i][j]==0 and verticalGrad[i][j]==0):\n",
        "          mag=0\n",
        "          angle = 0\n",
        "        else:\n",
        "          angle = math.degrees(math.atan(verticalGrad[i][j]/ horizontalGrad[i][j]))\n",
        "\n",
        "        #converting negative angles to positive\n",
        "        angle = angle%360 \n",
        "        \n",
        "        #converting them to range [0,180]\n",
        "        if angle>=180:\n",
        "          angle-=180\n",
        "        #print(\"mag is\",mag)\n",
        "        gradient_angles[i,j] = angle\n",
        "        newgradientImage[i,j] = mag\n",
        "  #print(newgradientImage.shape)\n",
        "  #print(horizontalGrad)\n",
        "  #print(verticalGrad)\n",
        "  # normalized_img1 = (255*(newgradientImage - np.min(newgradientImage))/np.ptp(newgradientImage)).astype(int)  \n",
        "  normalized_img = (newgradientImage/np.amax(newgradientImage))*255\n",
        "  normalized_img = normalized_img.astype(int)\n",
        "  #normalized_img = (newgradientImage * np.max(newgradientImage))/255\n",
        "  #print(normalized_img)\n",
        "  #print(gradient_angles)\n",
        "\n",
        "  return normalized_img,gradient_angles"
      ],
      "metadata": {
        "id": "0j24TWIoEFy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_histogram(array, weights):\n",
        "  hist = np.zeros(9)\n",
        "  weights = np.asarray(weights,dtype=float)\n",
        "  array = np.asarray(array,dtype=float)\n",
        "\n",
        "  #print(weights)\n",
        "  centers = [10.0,30.0,50.0,70.0,90.0,110.0,130.0,150.0,170.0]\n",
        "  bin1 = 0\n",
        "  bin2 = 0\n",
        "  proportion1=0.0\n",
        "  proportion2 = 0.0\n",
        "  for i in range(8):\n",
        "      for j in range(8):\n",
        "        if(array[i][j] in centers):\n",
        "          proportion1 = 1.0\n",
        "          proportion2 = 0.0\n",
        "          bin1 = int(array[i][j]//20)\n",
        "\n",
        "        elif(array[i][j]%20==0): #test corners\n",
        "          proportion1 = 0.5\n",
        "          proportion2 = 0.5\n",
        "          if(array[i][j]==180.0 or array[i][j]==0.0):\n",
        "            bin1 = 0\n",
        "            bin2 = 8\n",
        "          else:\n",
        "            bin1 = math.ceil((array[i][j]/20)+0.05) - 1\n",
        "            #hist[bin1] += 0.5*weights[i][j]\n",
        "            #hist[bin1-1] += 0.5*weights[i][j]\n",
        "            bin2 = bin1-1\n",
        "        else:\n",
        "          bin1 = math.ceil((array[i][j]/20)) - 1\n",
        "          if(bin1==9):\n",
        "            bin1 = 0\n",
        "            bin2 = 8\n",
        "          else:\n",
        "            if(bin1==8 and array[i][j]>centers[bin1]):\n",
        "              bin2 = 0\n",
        "            elif(array[i][j]<centers[bin1] and bin1==0):\n",
        "              bin2 = 8\n",
        "            elif(array[i][j]<centers[bin1]):\n",
        "              bin2 = bin1-1\n",
        "            else:\n",
        "              bin2 = bin1+1\n",
        "          proportion1 = 1 - (abs(array[i][j]-centers[bin1])/20.0)\n",
        "\n",
        "          proportion2 = 1-proportion1\n",
        "\n",
        "        hist[bin1] = hist[bin1] + (proportion1*weights[i][j])\n",
        "        hist[bin2] = hist[bin2] + (proportion2*weights[i][j])\n",
        "  #hist,_ = np.histogram(array,bins=9,range=(0,180),weights=weights)\n",
        "  #print(hist)\n",
        "  return hist"
      ],
      "metadata": {
        "id": "M2vNIsvGEePh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cell = [8, 8]\n",
        "incr = [8,8]\n",
        "bin_num = 9\n",
        "im_size = [160,96]\n",
        "\n",
        "def create_hog_features(grad_array,mag_array):\n",
        "  max_h = int(((grad_array.shape[0]-cell[0])/incr[0])+1)\n",
        "  max_w = int(((grad_array.shape[1]-cell[1])/incr[1])+1)\n",
        "  cell_array = []\n",
        "  w = 0\n",
        "  h = 0\n",
        "  i = 0\n",
        "  j = 0\n",
        "  #Creating 8X8 cells\n",
        "  while i<max_h:\n",
        "    w = 0\n",
        "    j = 0\n",
        "\n",
        "    while j<max_w:\n",
        "      gradient_array = grad_array[h:h+cell[0],w:w+cell[1]]\n",
        "      magnitude_array = mag_array[h:h+cell[0],w:w+cell[1]]\n",
        "      val = calculate_histogram(gradient_array,magnitude_array)\n",
        "      cell_array.append(val)\n",
        "      j += 1\n",
        "      w += incr[1]\n",
        "    i += 1\n",
        "    h += incr[0]\n",
        "\n",
        "  cell_array = np.reshape(cell_array,(max_h, max_w, bin_num))\n",
        "\t#normalising blocks of cells\n",
        "  block = [2,2]\n",
        "\t#here increment is 1\n",
        "\n",
        "  max_h = int((max_h-block[0])+1)\n",
        "  max_w = int((max_w-block[1])+1)\n",
        "  #max_h = 19\n",
        "  #max_w = 11\n",
        "  block_list = []\n",
        "  w = 0\n",
        "  h = 0\n",
        "  i = 0\n",
        "  j = 0\n",
        "  \n",
        "  while i<max_h:\n",
        "    w = 0\n",
        "    j = 0\n",
        "    while j<max_w:\n",
        "      for_norm = cell_array[h:h+block[0],w:w+block[1]]\n",
        "      #print(for_norm.shape)\n",
        "      mag = np.linalg.norm(for_norm)\n",
        "      arr_list = (for_norm/mag).flatten().tolist()\n",
        "      #print(\"hello\")\n",
        "      #print(len(arr_list))\n",
        "      block_list.extend(arr_list) #arr_list\n",
        "      j += 1\n",
        "      w += 1\n",
        "\n",
        "    i += 1\n",
        "    h += 1\n",
        "\n",
        "\t#returns a vextor array list of 7524 elements\n",
        "  return block_list\n",
        "\n",
        "\n",
        "images_hog_features = []\n",
        "\n"
      ],
      "metadata": {
        "id": "43UTTBMppXxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "  #Converting all the training images to gray and storing in an array\n",
        "  gray_images = []\n",
        "  for img in Train_pos:\n",
        "    if img.endswith(\"bmp\"):\n",
        "      #print(img)\n",
        "      image = cv2.imread(img)\n",
        "      gray_img = convert_to_gray(image)\n",
        "      gray_images.append((gray_img,1,img))\n",
        "\n",
        "  for img in Train_neg:\n",
        "    if img.endswith(\"bmp\"):\n",
        "      #print(img)\n",
        "      image = cv2.imread(img)\n",
        "      gray_img = convert_to_gray(image)\n",
        "      gray_images.append((gray_img,0,img))\n",
        "  #Applying prewitt operator and HOG to get the feature vectors of all the training images\n",
        "  images_hog_features = []\n",
        "  for i in gray_images:\n",
        "    mags,angles = prewitt_operator(i[0])\n",
        "    hog_features = create_hog_features(angles,mags)\n",
        "    hog_features = np.asarray(hog_features,dtype=float)\n",
        "    #hog_features = np.expand_dims(hog_features,axis=0)\n",
        "    hog_features = np.nan_to_num(hog_features)\n",
        "    #print(hog_features.shape)\n",
        "    savetxt(i[2].replace(\".bmp\",\".txt\"),hog_features.flatten())\n",
        "    images_hog_features.append(hog_features)\n",
        "  label = [i[1] for i in gray_images]\n",
        "  return images_hog_features,label"
      ],
      "metadata": {
        "id": "pyuHWzyAL7_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(images_hog_features,label):\n",
        "  for img in Test_neg + Test_pos:\n",
        "    test_img = cv2.imread(img)\n",
        "    test_gray = convert_to_gray(test_img)\n",
        "    magnitude,angle = prewitt_operator(test_gray)\n",
        "    hog_features = create_hog_features(angle,magnitude)\n",
        "    hog_features = np.asarray(hog_features,dtype=float)\n",
        "    #test_hog_features = np.expand_dims(hog_features,axis=0)\n",
        "    print(hog_features.shape)\n",
        "    hog_features = np.nan_to_num(hog_features)\n",
        "    distances = []\n",
        "    \n",
        "    images_hog_features = np.array(images_hog_features)\n",
        "    print(images_hog_features.shape)\n",
        "    #new_images_hog_features = images_hog_features[0]\n",
        "\n",
        "    for i in range(len(images_hog_features)):\n",
        "      sum = 0\n",
        "      sum_min = 0\n",
        "      for j in range(7524):\n",
        "        sum+=images_hog_features[i][j]\n",
        "        sum_min += min(images_hog_features[i][j],hog_features[j])\n",
        "      distances.append(sum_min/sum)\n",
        "\n",
        "    dictionary  = dict(zip(distances,label))\n",
        "    dict_new = [(i,j) for i,j in dictionary.items()]\n",
        "    dict_new.sort(key=lambda tup: tup[0],reverse=True)\n",
        "\n",
        "    neighbors = list()\n",
        "    for i in range(3):\n",
        "      neighbors.append(dict_new[i][1])\n",
        "    print(neighbors)\n",
        "    prediction = max(neighbors, key = neighbors.count)\n",
        "    if \"Neg\" in img:\n",
        "      print(\"No-Human\")\n",
        "    else:\n",
        "      print(\"Human\")\n",
        "    print(\"Human\" if prediction else \"No-Human\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "FAiMC90BMUeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_hog_features,label = train()\n",
        "test(images_hog_features,label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpPVqEWeK4zv",
        "outputId": "30edcf08-0651-4589-b50c-7441ca2c1dbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:51: RuntimeWarning: invalid value encountered in true_divide\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7524,)\n",
            "(20, 7524)\n",
            "[1, 0, 0]\n",
            "No-Human\n",
            "No-Human\n",
            "\n",
            "\n",
            "(7524,)\n",
            "(20, 7524)\n",
            "[0, 0, 1]\n",
            "No-Human\n",
            "No-Human\n",
            "\n",
            "\n",
            "(7524,)\n",
            "(20, 7524)\n",
            "[0, 0, 0]\n",
            "No-Human\n",
            "No-Human\n",
            "\n",
            "\n",
            "(7524,)\n",
            "(20, 7524)\n",
            "[0, 1, 1]\n",
            "No-Human\n",
            "Human\n",
            "\n",
            "\n",
            "(7524,)\n",
            "(20, 7524)\n",
            "[1, 0, 0]\n",
            "No-Human\n",
            "No-Human\n",
            "\n",
            "\n",
            "(7524,)\n",
            "(20, 7524)\n",
            "[1, 0, 0]\n",
            "Human\n",
            "No-Human\n",
            "\n",
            "\n",
            "(7524,)\n",
            "(20, 7524)\n",
            "[0, 1, 1]\n",
            "Human\n",
            "Human\n",
            "\n",
            "\n",
            "(7524,)\n",
            "(20, 7524)\n",
            "[1, 1, 1]\n",
            "Human\n",
            "Human\n",
            "\n",
            "\n",
            "(7524,)\n",
            "(20, 7524)\n",
            "[0, 1, 1]\n",
            "Human\n",
            "Human\n",
            "\n",
            "\n",
            "(7524,)\n",
            "(20, 7524)\n",
            "[1, 1, 1]\n",
            "Human\n",
            "Human\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.round(3.5)"
      ],
      "metadata": {
        "id": "8v-OSnvHOfc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6807b951-c35d-4f64-8d5d-c3bc3d76337b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DmqYwHT8T7k6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}